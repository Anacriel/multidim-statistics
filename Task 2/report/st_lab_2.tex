% XeLaTeX document
\documentclass[12pt, a4paper]{article}
\input{packages.tex}
\usepackage{fontspec}
\input{borders.tex}
\renewcommand{\baselinestretch}{1.4} 

\begin{document}

\input{title_page.tex}

\tableofcontents
\addtocontents{toc}{~\hfill\par}
\vfill ~
\setcounter{section}{0}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage 
\section*{Постановка задачи}
\addcontentsline{toc}{section}{Постановка задачи}

\indent{\indent Цель лабораторной работы –– восстановить зависимость между переменными с помощью модели линейной регрессии, рассчитать некоторые статистики, оценить полученную модель.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Ход работы}
\subsection{Построение модели и расчет характеристик}

\indent{\indent Пусть $X = \{x^m_0, \dots, x^m_n\}$ –– матрица независимых переменных размера $(n, m)$, $Y = \{y_0, \dots, y_n\}$ –– вектор наблюдений. В данной задаче $n = 15, m = 3$ Рассматривается модель $Y = f(A, X) + \epsilon$, где $\epsilon$ –– случайная величина, $A = \{a_0, ..., a_m\}^T$ –– вектор параметров. Требуется найти оценки зависимой переменной $\hat{Y}$ и параметров $\hat{A}$ такие, что $\hat{Y} = \hat{A}X$}

\indent{Найдем МНК-оценки параметров $a_0, \dots, a_m$. Они получены по формуле \ref{eq:lse_regression}. В таблице \ref{tab:reg_coeffs} представлены результаты минимизации.}

\begin{equation}
	\hat{A} = (X'X)^{-1}X'Y
	\label{eq:lse_regression}
\end{equation}


\begin{table}[htb]   
	\centering 
	\begin{tabular}{| c | c | c | c |}
		\hline
		$\hat{a}_0$ & $\hat{a}_1$ & $\hat{a}_2$ & $\hat{a}_3$ \\ 
		\hline
		1.451 & 0.370 & -0.003 & 5.711 \\ 
		\hline
	\end{tabular}
	\caption{Коэффициенты линейной регрессии}
	\label{tab:reg_coeffs}
\end{table}

\indent{Получим оценку дисперсии остатков $\hat{Y} - Y$ по формуле \ref{eq:res_var}. Получено значение $\hat{s^2} \sim 3.743$.}

\begin{equation}
	\hat{s}^2 = \frac{\sum_{i = 1}^{n}(\hat{y}_i - y_i)^2}{n - m - 1}
	\label{eq:res_var}
\end{equation}

\indent{Рассчитаем оценку матрицы ковариаций, которая определяется формулой \ref{eq:cov}. Результат представлен в таблице}

\begin{equation}
	\hat{cov(\hat A)} = \hat{s}^2 (X^TX)^{-1}
	\label{eq:cov}
\end{equation}

\begin{table}[htb]   
	\centering 
	\begin{tabular}{| c | c | c | c | c |}
		\hline
		$ $ & $\hat a_0$ & $\hat a_1$ & $\hat a_2$ & $\hat a_3$ \\ \hline
		$\hat a_0$ & 0.001 & -0.005 & 0.008 & 0.332 \\ \hline
		$\hat a_1$ & -0.005 & 0.082 & -0.144 & -5.358 \\ \hline
		$\hat a_2$ & -0.008 & -0.144 & 0.859 & 8.638 \\ \hline
		$\hat a_3$ & 0.332 & -5.358 & 8.638 & 363.339 \\
		\hline
	\end{tabular}
	\caption{Оценка матрицы ковариаций}
	\label{tab:cov}
\end{table}

\indent{Представим матрицу корреляций, элементы которой задаются формулой \ref{eq:cor}. Значения представлены в таблицу \ref{tab:cor} .}

\begin{equation}
	cor(\hat{A})_{ij} = \frac{(X^TX)^{-1}_{ij}}{\sqrt{(X^TX)^{-1}_{ii} (X^TX)^{-1}_{jj}}}
	\label{eq:cor}
\end{equation}

\begin{table}[htb]   
	\centering 
	\begin{tabular}{| c | c | c | c | c |}
		\hline
		$ $ & $\hat a_0$ & $\hat a_1$ & $\hat a_2$ & $\hat a_3$ \\ \hline
		$\hat a_0$ & 1 & -0.608 & -0.273 & 0.575 \\ \hline
		$\hat a_1$ & -0.608 & 1 & -0.544 & -0.982 \\ \hline
		$\hat a_2$ & -0.273 & -0.544 & 1 & 0.489 \\ \hline
		$\hat a_3$ & 0.575 & -0.982 & 0.489 & 1 \\
		\hline
	\end{tabular}
	\caption{Корреляционная матрица}
	\label{tab:cor}
\end{table}

\clearpage

\indent{ Построим графики $\hat{Y}$ и $Y$:}

\begin{figure}[h!]
	\centering
	\includegraphics[width=8cm, height=8cm]{y_y_hat}
	\caption{Оцененные и реальные значения}
	\label{fig:y_y_hat}
\end{figure}

\indent{Построим гистограмму остатков $\hat{Y} - Y$ для оценки адекватности регрессионной модели.}

\begin{figure}[h!]
	\centering
	\includegraphics[width=8cm, height=8cm]{res_hist}
	\caption{Гистограмма регрессионных остатков}
	\label{fig:res_hist}
\end{figure}

\indent{Вычислим оценки коэффициента детерминации и скорректированного коэффициента детерминации по формулам:}

\begin{equation}
	R^2 = \frac{\sum_i^{}(\hat{y} - \overline{y})^2}{\sum_i^{}(y - \overline{y})^2}
	\label{eq:determ}
\end{equation}

\begin{equation}
	R_{adj}^2 = \frac{R^2 (n - 1) - m + 1}{(n - m)},
	\label{eq:determ_adj}
\end{equation}
где $n$ –– число наблюдений, $m$ –– число параметров модели

\indent{Были получены следующие значения: $R^2 \sim 0.996, \;\; R_{adj}^2 \sim 0.995$. }

\subsection{Проверка гипотез}

\indent{\indent Проверим гипотезу о равенстве нулю для близких к нулю коэффициентов регрессии, то есть $H_0: \; a_i = 0, i = 1, 2$. Для этого рассчитаем статистику, имеющую распределение Стьюдента с $n - m = 11$ степенями свободы:}

\begin{equation}
	t = \frac{\hat a_i}{\hat{s}_{\hat a_i}}
	\label{eq:t_stat}
\end{equation}

\indent{В результате получены значения статистик, указанные в таблице \ref{tab:t_stat_per_coef}. Квантили распределения Стьюдента уровней $1 - \alpha / 2$ при $\alpha = 0.05, 0.25$ –– $t_{11, 0.975} \sim 2.2$, $t_{11, 0.875} \sim 1.214$.}

\begin{table}[htb]   
	\centering 
	\begin{tabular}{| c | c | c | c | c |}
		\hline
		$ $ & $a_1$ & $a_2$ \\ \hline
		$t$ & 12.241 & -0.011 \\
		\hline
	\end{tabular}
	\caption{Значение распределения Стьюдента с 11 степенями свободы}
	\label{tab:t_stat_per_coef}
\end{table}

\indent{Исходя из полученных результатов, гипотеза $H_0$ на уровнях значимости 0.05, 0.25 отвергается для коэффициента $a_1$, так как значение статистики находится за пределами $+-t_{11, 0.975}, +-t_{11, 0.875}$. Для коэффициента $a_2$ на уровнях значимости 0.05, 0.25 гипотеза не отвергается. Заключаем, что коэффициент $a_2$ не значим.}

\indent{Перейдем к редуцированной модели без коэффициента $a_2$. Найдем оценки ее коэффициентов по формуле \ref{eq:lse_regression}.}

\clearpage

\begin{table}[htb]   
	\centering 
	\begin{tabular}{| c | c | c | c |}
		\hline
		$\hat{a}^r_0$ & $\hat{a}^r_1$ & $\hat{a}^r_2$ \\ 
		\hline
		1.255 & 0.370 & 5.706 \\ 
		\hline
	\end{tabular}
	\caption{Коэффициенты редуцированной ($r$) линейной регрессии}
	\label{tab:reduced_reg_coeffs}
\end{table}

\indent{Построим графики $\hat{Y}^r$ и $Y^r$:}

\begin{figure}[h!]
	\centering
	\includegraphics[width=8cm, height=8cm]{y_y_hat}
	\caption{Оцененные и реальные значения редуцированной ($r$) модели}
	\label{fig:y_y_hat_reduced}
\end{figure}

\indent{Рассчитаем оценку дисперсии по формуле \ref{eq:res_var}. Было получено значение $(\hat{s}^2)^r \sim 3.743 ~\sim \hat{s}^2$. Видим, что дисперсия практически не изменилась, значит, далее будем работать с редуцированной моделью. Теперь $m = 3$.}

%%%%%%%%%%%%%%

\indent{Проверим гипотезу об одновременном равенстве нулю всех коэффициентов, то есть, $H_0: a_i^r = 0, \forall i = 0, \dots, n$. Для этого посчитаем статистику теста:}

\begin{equation}
	F = \frac{R^2 / (m - 1))}{(1 - R^2)(n - m)} \sim F(m - 1, n - m)
	\label{eq:t_stat}
\end{equation}

\vspace{1cm}

\indent{Вычислим статистику для редуцированной модели. Потребуется рассчитать коэффициенты детерминации: $(R^2)^r \sim 0.996, (R^2_{adj})^r \sim 0.995$. }

\indent{Критическое значения статистики $F_{0.95}(2, 12) \sim 3.885$. При расчетах получили значение $F \sim 1668.079$. Это значение гораздо больше критического, поэтому гипотеза о равенстве всех коэффициентов регресии нулю отвергается на уровне значимости 0.5.}

\indent{Проверим гипотезу о равенстве коэффициентов двух регрессий, разбив имеющуюся выборку на 2 части. Для этого рассчитаем статистику:}

\begin{equation}
	F = \frac{((S - (S_1 + S_2)) / m)}{(S_1 + S_2) / (n - 2m)} \sim F(m, n - 2m),
	\label{eq:f_chow}
\end{equation}
где $S, \; S_1, \; S_2$ –– суммы квадратов остатков общей модели и моделей на двух подвыборках соответственно.

\indent{Значение распределения Фишера на уровне значимости 0.05 $F_{0.95}(3, 9) \sim 3.863$. При расчетах по формуле \ref{eq:f_chow} было получено значение $F \sim 2.656 < F_{0.95}(3, 9)$, следовательно, гипотеза о равенстве коэффициентов двух регрессий не отвергается.}

\subsection{Доверительные интервалы}

\indent{\indent Построим индивидуальные доверительные интервалы для параметров линейной регрессии на уровне значимости $\alpha = 0.05$. Неравенство для доверительного интервала значений неизвестного коэффициента:}

\begin{equation}
	\hat{a}_i - t_{cr} \cdot S_{\hat{a}_i} < a_i < \hat{a}_i + t_{cr} \cdot S_{\hat{a}_i}
	\label{eq:conf_interval}
\end{equation}

\begin{table}[htb]   
	\centering 
	\begin{tabular}{| c | c | c | c |}
		\hline
		$ $ & $a_0^r$ & $a_1^r$ & $a_2^r$ \\ \hline
		$left$ & 0.320 & 4.099 & -6.217 \\ \hline
		$right$ & 0.420 & 7.313 & 8.727 \\
		\hline
	\end{tabular}
	\caption{Доверительные интервалы для коэффициентов редуцированной ($r$) регресии}
	\label{tab:conf_interval}
\end{table}

\clearpage

\indent{Теперь построим совместные доверительные интервалы по принципу Тьюки}

\begin{table}[htb]   
	\centering 
	\begin{tabular}{| c | c | c | c |}
		\hline
		$ $ & $a_0^r$ & $a_1^r$ & $a_2^r$ \\ \hline
		$left$ & 0.308 & 3.700 & -8.069 \\ \hline
		$right$ & 0.432 & 7.712 & 10.579  \\
		\hline
	\end{tabular}
	\caption{Доверительные интервалы по методу Тьюки для коэффициентов редуцированной ($r$) регресии}
	\label{tab:conf_interval_tukey}
\end{table}

\indent{Приведем доверительные интервалы, используя неравенство Чебышева:}

\begin{equation}
	P(|\hat{a}_i - a_i| \le \tau s_i) \ge 1 - \frac{1}{\tau^2},
	\label{eq:conf_interval_cheb}
\end{equation}
где $\tau = \sqrt{20}$ для $\alpha = 0.05$

\begin{table}[htb]   
	\centering 
	\begin{tabular}{| c | c | c | c |}
		\hline
		$ $ & $a_0^r$ & $a_1^r$ & $a_2^r$ \\ \hline
		$left$ & 0.263 & 2.229 & -14.907 \\ \hline
		$right$ & 0.477 & 9.183 & 17.416 \\
		\hline
	\end{tabular}
	\caption{Доверительные интервалы по Чебышеву для коэффициентов редуцированной ($r$) регресии}
	\label{tab:conf_interval_cheb}
\end{table}

\indent{Заметим, что доверительные интервалы Чебышева гораздо шыре предыдущих.}

\subsection{Прогноз модели}

\indent{\indent Протестируем модель регрессии на случайном наблюдении, не участвовавшем в построении ее коэффициентов. Были получены следующие значения для наблюдения с индексом 14:}

\begin{itemize}
	\item $\hat{y}^r_{test} \sim 188.530, y^r_{test} \sim 186.405$
	\item $(\hat{s}_{test}^2)^r \sim 4.249$
	\item Индивидуальный доверительный интервал при $\alpha = 0.1$: $[184.828, 192.232]$
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}

\indent{\indent Полученная модель линейной регрессии достаточно качественная. Это объясняется близостью коэффициента детерминации к единице, то есть, статистическая связь между зависимой $Y$ и независимой $X$ переменными функциональна, значения $Y$ практически полностью определяются значениями факторов $X$.}

\indent{В ходе работы были проверены гипотезы, удалось выяснить, что в полной модели присутствуют коэффициенты, гипотеза о равенстве нулю которых не отвергается. была получена редуцированная модель без фактора $a_2$. Исключение этого коэффициента не повлекло повышения дисперсии остатков, уменьшения коэффициентов детерминации, поэтому остальные расчеты приведены именно для редуцированной модели.}

\indent{Наиболее узкими доверительными интервалами получились индивидуальные доверительные интервалы. Интервалы, полученные с помощью неравенства Чебышева, вышли наиболее широкими, что говорит о худшем результате. Этот метод оценки непараметрический, никаких предположений о распределении данных не требуется. }

\clearpage

\bibliographystyle{splncs04}
\bibliography{mybibliography}


\end{document}{}